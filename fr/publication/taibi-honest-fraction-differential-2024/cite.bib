@inproceedings{taibiHonestFractionDifferential2024,
 abstract = {Over the last decades, differential privacy (DP) has become a standard notion of privacy. It allows to measure how much sensitive information an adversary could infer from a result (statistical model, prediction, etc.) he obtains. In privacy-preserving federated machine learning, one aims to learn a statistical model from data owned by multiple data owners without revealing their sensitive data. A common strategy is to use secure multi-party computation (SMPC) to avoid revealing intermediate results. However, DP assumes a very strong adversary who is able to know all information in the dataset except the targeted secret, while most SMPC methods assume a clearly less strong adversary, e.g., it is common to assume that the adversary has bounded computational power and can corrupt only a minority of the data owners (honest majority). As a chain is not stronger than its weakest part, in such combinations the DP provides an overly strong protection at an unnecessarily high cost in terms of utility. We propose honest fraction differential privacy, which is similar to differential privacy but assumes that the adversary can only collude with data owners covering part of the data. This assumption is very similar to the assumptions made by many SMPC strategies. We illustrate this idea by considering the application to the specific task of unregularized linear regression without bias on sufficiently large datasets.},
 author = {Taibi, Imane and Ramon, Jan},
 date = {2024-06-24},
 doi = {10.1145/3658664.3659655},
 eventtitle = {ACM Workshop on Information Hiding and Multimedia Security},
 file = {C:\UsersÄ£228481\Documents\50biblio\zotero_\Taibi_Ramon_2024_Honest Fraction Differential Privacy.pdf},
 langid = {english},
 pages = {1},
 title = {Honest Fraction Differential Privacy},
 url = {https://inria.hal.science/hal-04610199},
 urldate = {2025-01-29}
}
