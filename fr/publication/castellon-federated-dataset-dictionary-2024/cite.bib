@inproceedings{castellonFederatedDatasetDictionary2024,
 abstract = {In this article, we propose an approach for federated domain adaptation, a setting where data heterogeneity exists among clients and some have unlabeled data. The proposed framework, FedDaDiL, tackles the resulting challenge through dictionary learning of empirical distributions. In our setting, clients' distributions represent particular domains, and FedDaDiL collectively trains a federated dictionary of empirical distributions. In particular, we build upon the Dataset Dictionary Learning framework by designing communication protocols and aggregation operations in a collaborative setting. The chosen protocols keep clients' data private, thus enhancing overall privacy compared to its centralized counterpart. We empirically demonstrate that our approach successfully labels the target domain with extensive experiments on (i) Caltech-Office, (ii) TEP, and (iii) CWRU benchmarks. Furthermore, we compare our method to its centralized counterpart and other benchmarks in federated domain adaptation.},
 author = {Castellon, Fabiola Espinoza and Montesuma, Eduardo Fernandes and Mboula, Fred Maurice Ngole and Mayoue, Aurélien and Souloumiac, Antoine and Gouy-Pailler, Cedric},
 date = {2024-04-14},
 doi = {10.1109/ICASSP48485.2024.10447236},
 eventtitle = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing},
 file = {C\:\\Users\ģ228481\\Documents\\50biblio\\zotero\\IEEE\\Castellon et al_2024_Federated dataset dictionary learning for multi-source domain adaptation.pdf;C\:\\Users\\2̧28481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\SJ8MSJZF\\c-̧05115469v1.html},
 langid = {english},
 pages = {10447236},
 publisher = {IEEE},
 title = {Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation},
 url = {https://cea.hal.science/cea-05115469},
 urldate = {2025-10-16}
}
