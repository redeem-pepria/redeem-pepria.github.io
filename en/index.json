
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["Cédric Gouy-Pailler"],"categories":null,"content":"Cédric Gouy-Pailler holds an engineering degree in electronics and signal processing from PHELMA (ex-ENSERG), Grenoble-INP, he received a doctorate in signal processing in 2009 at GIPSA-lab (Grenoble INP). Senior Expert at CEA since 2021, he is now leading the Artificial Intelligence and Machine Learning laboratory at CEA LIST. He is working on innovative machine learning algorithms, with the objective of developing robust AI in adversarial contexts, and compatible with high privacy standards, through the use of homomorphic encryption and differential privacy. Cédric Gouy-Pailler has been involved in various National and European projects, involving both academic and industrials partners. He has been technical CEA leader (eCo-fev, EU project, 2012-2015), Work Package leader (STARLIGHT, EU project, 2021-2025, involving 52 partners), and project coordinator (StreamOPS, national 3 partners, 2018-2021 ; KINAITICS, EU project, 7 partners, 2022-2025).\n","date":1738627200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738627200,"objectID":"e92b45342344fb7285c16b647f500037","permalink":"https://redeem-pepria.github.io/en/author/cedric-gouy-pailler/","publishdate":"2025-02-04T00:00:00Z","relpermalink":"/en/author/cedric-gouy-pailler/","section":"authors","summary":"Cédric Gouy-Pailler holds an engineering degree in electronics and signal processing from PHELMA (ex-ENSERG), Grenoble-INP, he received a doctorate in signal processing in 2009 at GIPSA-lab (Grenoble INP). Senior Expert at CEA since 2021, he is now leading the Artificial Intelligence and Machine Learning laboratory at CEA LIST. He is working on innovative machine learning algorithms, with the objective of developing robust AI in adversarial contexts, and compatible with high privacy standards, through the use of homomorphic encryption and differential privacy. Cédric Gouy-Pailler has been involved in various National and European projects, involving both academic and industrials partners. He has been technical CEA leader (eCo-fev, EU project, 2012-2015), Work Package leader (STARLIGHT, EU project, 2021-2025, involving 52 partners), and project coordinator (StreamOPS, national 3 partners, 2018-2021 ; KINAITICS, EU project, 7 partners, 2022-2025).\n","tags":null,"title":"Cédric Gouy-Pailler","type":"authors"},{"authors":["Julien Nicolas"],"categories":null,"content":"To be completed\n","date":1738108800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738108800,"objectID":"4ed72accaa85bd5f22c784547a8b63e4","permalink":"https://redeem-pepria.github.io/en/author/julien-nicolas/","publishdate":"2025-01-29T09:28:04.451026Z","relpermalink":"/en/author/julien-nicolas/","section":"authors","summary":"To be completed\n","tags":null,"title":"Julien Nicolas","type":"authors"},{"authors":["Mohamed Maouche"],"categories":null,"content":"Mohamed Maouche is a researcher at Inria Lyon (ISFP) and member of the PRIVATICS team since 2022. His interest is to build robust machine learning systems that manage a good trade-off between privacy, security and utility. This includes working on data anonymization and privacy preserving machine learning with robust aggregation. Previously, he was a one-year post-doc whithin the Chaire DSVD supported by Renault and Labex IMU working on privacy issues in Federated Learning. He also spent two years as a post-doc in MAGNET Team (Inria Lille) to work on speech anonymization. He defended his PhD from Insa Lyon in 2019 on the subject of Location privacy.\n","date":1738022400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738022400,"objectID":"42f96f22a28b2bde47c757c871c3ea68","permalink":"https://redeem-pepria.github.io/en/author/mohamed-maouche/","publishdate":"2025-01-29T09:28:04.451026Z","relpermalink":"/en/author/mohamed-maouche/","section":"authors","summary":"Mohamed Maouche is a researcher at Inria Lyon (ISFP) and member of the PRIVATICS team since 2022. His interest is to build robust machine learning systems that manage a good trade-off between privacy, security and utility. This includes working on data anonymization and privacy preserving machine learning with robust aggregation. Previously, he was a one-year post-doc whithin the Chaire DSVD supported by Renault and Labex IMU working on privacy issues in Federated Learning. He also spent two years as a post-doc in MAGNET Team (Inria Lille) to work on speech anonymization. He defended his PhD from Insa Lyon in 2019 on the subject of Location privacy.\n","tags":null,"title":"Mohamed Maouche","type":"authors"},{"authors":["Sonia Ben Mokhtar"],"categories":null,"content":"I have been a CNRS researcher at the LIRIS lab since October 2009. Since 2017, I am also the leader of the distributed systems and information retrieval group (DRIM). Before joining CNRS, I was a research associate at University College London (UCL) for two years, working with Licia Capra. I received my PhD in 2007 from University Pierre et Marie Curie (Paris 6), which I did under the supervision of Valérie Issarny and Nikolaos Georgantas in the former INRIA ARLES project-team (currently MiMove).\n","date":1738022400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738022400,"objectID":"8a457e262205130de8c55f859f13c478","permalink":"https://redeem-pepria.github.io/en/author/sonia-ben-mokhtar/","publishdate":"2025-01-29T09:28:04.451026Z","relpermalink":"/en/author/sonia-ben-mokhtar/","section":"authors","summary":"I have been a CNRS researcher at the LIRIS lab since October 2009. Since 2017, I am also the leader of the distributed systems and information retrieval group (DRIM). Before joining CNRS, I was a research associate at University College London (UCL) for two years, working with Licia Capra. I received my PhD in 2007 from University Pierre et Marie Curie (Paris 6), which I did under the supervision of Valérie Issarny and Nikolaos Georgantas in the former INRIA ARLES project-team (currently MiMove).\n","tags":null,"title":"Sonia Ben Mokhtar","type":"authors"},{"authors":["Brandon A. Mosqueda González"],"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1735689600,"objectID":"11791f3594bf992ef830d352b2823ec3","permalink":"https://redeem-pepria.github.io/en/author/brandon-a.-mosqueda-gonzalez/","publishdate":"2025-01-28T21:08:55.802492Z","relpermalink":"/en/author/brandon-a.-mosqueda-gonzalez/","section":"authors","summary":"","tags":null,"title":"Brandon A. Mosqueda González","type":"authors"},{"authors":["Aymeric Dieuleveut"],"categories":null,"content":"To be completed\n","date":1733097600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1733097600,"objectID":"6072d47e443fd9d457d66f6764bd1988","permalink":"https://redeem-pepria.github.io/en/author/aymeric-dieuleveut/","publishdate":"2025-01-28T21:08:55.786645Z","relpermalink":"/en/author/aymeric-dieuleveut/","section":"authors","summary":"To be completed\n","tags":null,"title":"Aymeric Dieuleveut","type":"authors"},{"authors":["Kevin Scaman"],"categories":null,"content":"To be completed\n","date":1726185600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1726185600,"objectID":"8478952da8934ada6c3295340c345d1b","permalink":"https://redeem-pepria.github.io/en/author/kevin-scaman/","publishdate":"2025-01-28T21:08:55.84915Z","relpermalink":"/en/author/kevin-scaman/","section":"authors","summary":"To be completed\n","tags":null,"title":"Kevin Scaman","type":"authors"},{"authors":["Jan Ramon"],"categories":null,"content":"To be completed\n","date":1719187200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1719187200,"objectID":"b0458a5182da4ba951057101c34fbffc","permalink":"https://redeem-pepria.github.io/en/author/jan-ramon/","publishdate":"2025-01-29T13:18:02.819657Z","relpermalink":"/en/author/jan-ramon/","section":"authors","summary":"To be completed\n","tags":null,"title":"Jan Ramon","type":"authors"},{"authors":["Antonella Del Pozzo"],"categories":null,"content":"To be completed\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"16ffc94c4f7436ef6da318dc0623bb89","permalink":"https://redeem-pepria.github.io/en/author/antonella-del-pozzo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/antonella-del-pozzo/","section":"authors","summary":"To be completed\n","tags":null,"title":"Antonella Del Pozzo","type":"authors"},{"authors":["Arnaud Descours"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4b325dd492b3e3a337a776a91ba98b5c","permalink":"https://redeem-pepria.github.io/en/author/arnaud-descours/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/arnaud-descours/","section":"authors","summary":"","tags":null,"title":"Arnaud Descours","type":"authors"},{"authors":["Rebecca Clain","Eduardo Fernandes Montesuma","Fred Maurice Ngole Mboula"],"categories":null,"content":"","date":1743465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1743465600,"objectID":"100a80d149495830bf1541e6322f738f","permalink":"https://redeem-pepria.github.io/en/publication/clain-decentralized-federated-dataset-2025/","publishdate":"2025-01-28T21:08:55.624915Z","relpermalink":"/en/publication/clain-decentralized-federated-dataset-2025/","section":"publication","summary":"","tags":["CEA-distrAI"],"title":"Decentralized Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation","type":"publication"},{"authors":["Cédric Gouy-Pailler"],"categories":null,"content":"Conference AI, Science, and Society\nWe are excited to share that the REDEEM project will be actively represented at the upcoming AI Conference 2025 at IP Paris!\nSession on Trustworthy AI Aymeric Dieuleveut will contribute to the discussion on trustworthy AI, providing insights into the latest advancements in secure and reliable AI systems.\nPoster Session Batiste Le Bars (INRIA) will present his work on “Improved Stability and Generalization Guarantees of the Decentralized SGD Algorithm.”\nThis research challenges prior claims on decentralized learning, demonstrating that decentralized stochastic gradient descent (SGD) can match centralized approaches in generalization while benefiting from communication-aware optimizations.\nJoin us at AI Conference 2025 to engage with cutting-edge research in AI, federated learning, and decentralized optimization!\n","date":1738627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738627200,"objectID":"88806b93c3d2ce729873bc904789d684","permalink":"https://redeem-pepria.github.io/en/post/2025-02-04_aiactionsummit/","publishdate":"2025-02-04T00:00:00Z","relpermalink":"/en/post/2025-02-04_aiactionsummit/","section":"post","summary":"Conference AI, Science, and Society\nWe are excited to share that the REDEEM project will be actively represented at the upcoming AI Conference 2025 at IP Paris!\nSession on Trustworthy AI Aymeric Dieuleveut will contribute to the discussion on trustworthy AI, providing insights into the latest advancements in secure and reliable AI systems.\n","tags":null,"title":"Join us at AI Action Summit 6-7/02/2025 at Ecole Polytechnique","type":"post"},{"authors":["Julien Nicolas"],"categories":null,"content":"Secure Federated Graph-Filtering for Recommender Systems\nRecommender systems rely on graph-based filters, but their centralized computation poses privacy and security risks. Our work introduces two decentralized frameworks that securely compute key graph components without centralizing user data. Leveraging Multi-Party Computation and distributed spectral methods, we ensure privacy while maintaining predictive accuracy. Our second approach further optimizes efficiency through low-rank approximations, balancing performance and communication costs. Experiments on benchmark datasets show that our methods match state-of-the-art accuracy while preserving data confidentiality. This work paves the way for privacy-preserving, decentralized recommender architectures.\nYou can already read this publication on arxiv: Secure Federated Graph-Filtering for Recommender Systems\nScientific Publications: Stay updated with the latest research outputs from our team, published in top-tier conferences and journals. Publications\n","date":1738108800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738108800,"objectID":"0e73420355239216986ac752617bdf0c","permalink":"https://redeem-pepria.github.io/en/post/2025-01-29_new-preprint-available/","publishdate":"2025-01-29T00:00:00Z","relpermalink":"/en/post/2025-01-29_new-preprint-available/","section":"post","summary":"Secure Federated Graph-Filtering for Recommender Systems\nRecommender systems rely on graph-based filters, but their centralized computation poses privacy and security risks. Our work introduces two decentralized frameworks that securely compute key graph components without centralizing user data. Leveraging Multi-Party Computation and distributed spectral methods, we ensure privacy while maintaining predictive accuracy. Our second approach further optimizes efficiency through low-rank approximations, balancing performance and communication costs. Experiments on benchmark datasets show that our methods match state-of-the-art accuracy while preserving data confidentiality. This work paves the way for privacy-preserving, decentralized recommender architectures.\n","tags":null,"title":"New Preprint Available","type":"post"},{"authors":null,"categories":null,"content":"We’re thrilled to announce that the new REDEEM Project website is officially live!\nExplore everything about the REDEEM project, including:\nProject Description: Learn about our mission to advance decentralized, privacy-preserving, and resilient AI systems. Project description Scientific Publications: Stay updated with the latest research outputs from our team, published in top-tier conferences and journals. Publications Job Opportunities: Want to work with us? Discover open positions in our team, including exciting PhD and postdoctoral opportunities. Job opportunities We’ll continue to update the site regularly with news, publications, and opportunities. Make sure to bookmark it and follow our journey!\nThank you for your support,\nThe REDEEM Project Team\n","date":1738022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738022400,"objectID":"1cdc6a246d8c9fc6edb0f9bf7a24cfde","permalink":"https://redeem-pepria.github.io/en/post/2025-01-28_new-website-live/","publishdate":"2025-01-28T00:00:00Z","relpermalink":"/en/post/2025-01-28_new-website-live/","section":"post","summary":"We’re thrilled to announce that the new REDEEM Project website is officially live!\nExplore everything about the REDEEM project, including:\nProject Description: Learn about our mission to advance decentralized, privacy-preserving, and resilient AI systems. Project description Scientific Publications: Stay updated with the latest research outputs from our team, published in top-tier conferences and journals. Publications Job Opportunities: Want to work with us? Discover open positions in our team, including exciting PhD and postdoctoral opportunities. Job opportunities We’ll continue to update the site regularly with news, publications, and opportunities. Make sure to bookmark it and follow our journey!\n","tags":null,"title":"Our New REDEEM Website is Live!","type":"post"},{"authors":null,"categories":null,"content":"","date":1738022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738022400,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://redeem-pepria.github.io/en/people/","publishdate":"2025-01-28T00:00:00Z","relpermalink":"/en/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":["Julien Nicolas","César Sabater","Mohamed Maouche","Sonia Ben Mokhtar","Mark Coates"],"categories":null,"content":"","date":1738022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738022400,"objectID":"e0e8d97b5d59cbcc8050eefc405fb874","permalink":"https://redeem-pepria.github.io/en/publication/nicolas-secure-federated-graph-filtering-2025/","publishdate":"2025-01-29T09:28:04.451026Z","relpermalink":"/en/publication/nicolas-secure-federated-graph-filtering-2025/","section":"publication","summary":"Recommender systems often rely on graph-based filters, such as normalized item-item adjacency matrices and low-pass filters. While effective, the centralized computation of these components raises concerns about privacy, security, and the ethical use of user data. This work proposes two decentralized frameworks for securely computing these critical graph components without centralizing sensitive information. The first approach leverages lightweight Multi-Party Computation and distributed singular vector computations to privately compute key graph filters. The second extends this framework by incorporating low-rank approximations, enabling a trade-off between communication efficiency and predictive performance. Empirical evaluations on benchmark datasets demonstrate that the proposed methods achieve comparable accuracy to centralized state-of-the-art systems while ensuring data confidentiality and maintaining low communication costs. Our results highlight the potential for privacy-preserving decentralized architectures to bridge the gap between utility and user data protection in modern recommender systems.","tags":["Computer Science - Cryptography and Security","Computer Science - Information Retrieval"],"title":"Secure Federated Graph-Filtering for Recommender Systems","type":"publication"},{"authors":["Feodor Dragan","Guillaume Ducoffe","Michel Habib","Laurent Viennot"],"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"92044013f6ef8ba1b09df8b393132d84","permalink":"https://redeem-pepria.github.io/en/publication/dragan-certificates-subquadratic-time-computation-2025/","publishdate":"2025-01-28T21:08:55.642802Z","relpermalink":"/en/publication/dragan-certificates-subquadratic-time-computation-2025/","section":"publication","summary":"In the context of fine-grained complexity, we investigate the notion of certificate enabling faster polynomialtime algorithms. We specifically target radius (minimum eccentricity), diameter (maximum eccentricity), and all-eccentricity computations for which quadratic-time lower bounds are known under plausible conjectures. In each case, we introduce a notion of certificate as a specific set of nodes from which appropriate bounds on all eccentricities can be derived in subquadratic time when this set has sublinear size. The existence of small certificates is a barrier against SETH-based lower bounds for these problems. We indeed prove that for graph classes with small certificates, there exist randomized subquadratic-time algorithms for computing the radius, the diameter, and all eccentricities respectively.Moreover, these notions of certificates are tightly related to algorithms probing the graph through one- to-all distance queries and allow to explain the efficiency of practical radius and diameter algorithms from the literature. Our formalization enables a novel primal-dual analysis of a classical approach for diameter computation that leads to algorithms for radius, diameter and all eccentricities with theoretical guarantees with respect to certain graph parameters. This is complemented by experimental results on various types of real-world graphs showing that these parameters appear to be low in practice. Finally, we obtain refined results for several graph classes.*This work was supported by the French ANR projects ANR-22-CE48-0001 (TEMPOGRAL), ANR-24-CE48-4377 (GODASse) and ANR-23-PEIA-005 (REDEEM).","tags":["INRIA-ARGO"],"title":"Certificates in P and Subquadratic-Time Computation of Radius, Diameter, and All Eccentricities in Graphs","type":"publication"},{"authors":null,"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"8af25929ca8895de4f7cefaa32947b2c","permalink":"https://redeem-pepria.github.io/en/joboffer/inria_janramon_engineer/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/en/joboffer/inria_janramon_engineer/","section":"joboffer","summary":"Follow the link to get more details on this opportunity.","tags":["engineer"],"title":"Engineer - Scientific programmer in privacy-preserving federate learning with applications in oncology","type":"joboffer"},{"authors":null,"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"7bc14dd430089e42e54f32d8f0b522b7","permalink":"https://redeem-pepria.github.io/en/joboffer/inria_janramon_interns/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/en/joboffer/inria_janramon_interns/","section":"joboffer","summary":"Contact Jan Ramon if you are interested.","tags":["intern"],"title":"Interships in privacy-preserving decentralized machine learning","type":"joboffer"},{"authors":["Brandon A. Mosqueda González","Omar Hasan","Lionel Brunie"],"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"6dd9d8b1c2d5645d3583239c66ff15f4","permalink":"https://redeem-pepria.github.io/en/publication/mosquedagonzalez-mitigation-sybilbased-poisoning-2025/","publishdate":"2025-01-28T21:08:55.802492Z","relpermalink":"/en/publication/mosquedagonzalez-mitigation-sybilbased-poisoning-2025/","section":"publication","summary":"Decentralized learning enables collaborative machine learning with enhanced privacy by allowing participants to train models locally and share updates for aggregation instead of sharing raw data. However, such systems are vulnerable to poisoning attacks that may compromise the learning process. This threat becomes even more severe when combined with sybil attacks, where adversaries contribute numerous malicious updates with minimal effort, amplifying their impact. To overcome these challenges, particularly in the permissionless setup, we propose SyDeLP, a blockchain-enabled protocol for decentralized learning. SyDeLP integrates byzantine tolerant aggregation for poisoning mitigation with a novel Verifiable Delay Puzzle to counter sybil attacks requiring Proofs of Work to participate. Honest behavior is incentivized by dynamically reducing puzzle difficulty, decreasing the computational burden for honest nodes over time. Empirical evaluations conducted on two benchmark datasets across four types of poisoning attack demonstrate that SyDeLP consistently outperforms existing solutions in terms of poisoning resilience.","tags":["CNRS-LIRIS"],"title":"Mitigation of Sybil-based Poisoning Attacks in Permissionless Decentralized Learning","type":"publication"},{"authors":null,"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"40cc3e5a0b716668fb694847d0c18408","permalink":"https://redeem-pepria.github.io/en/joboffer/inria_janramon_phd/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/en/joboffer/inria_janramon_phd/","section":"joboffer","summary":"See the link.","tags":["phd"],"title":"PhD Position F/M PhD student on privacy-preserving federate learning with applications in oncology","type":"joboffer"},{"authors":null,"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"54fbe2e4d15da53a91ecf56993b35204","permalink":"https://redeem-pepria.github.io/en/joboffer/inria_janramon_postdoc/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/en/joboffer/inria_janramon_postdoc/","section":"joboffer","summary":"We hope the post-doc can bring new expertise to the group and/or can help intensifying collaboration in the project consortium.  He will collaborate closely with the other group members on realizing the research objectives of the project.  Engineers in the team can support the prototyping and validation.","tags":["postdoc"],"title":"Post-Doctoral Research Visit F/M privacy preserving federated learning with applications in medical domains","type":"joboffer"},{"authors":["Ousmane Touat","Jezekael Brunon","Yacine Belal","Julien Nicolas","Mohamed Maouche","César Sabater","Sonia Ben Mokhtar"],"categories":null,"content":"","date":1734393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1734393600,"objectID":"050c63c4d82f0e0eb0aac8839df01953","permalink":"https://redeem-pepria.github.io/en/publication/touat-scrutinizing-vulnerability-decentralized-2024/","publishdate":"2025-01-28T21:08:55.86882Z","relpermalink":"/en/publication/touat-scrutinizing-vulnerability-decentralized-2024/","section":"publication","summary":"The primary promise of decentralized learning is to allow users to engage in the training of machine learning models in a collaborative manner while keeping their data on their premises and without relying on any central entity. However, this paradigm necessitates the exchange of model parameters or gradients between peers. Such exchanges can be exploited to infer sensitive information about training data, which is achieved through privacy attacks (e.g Membership Inference Attacks -- MIA). In order to devise effective defense mechanisms, it is important to understand the factors that increase/reduce the vulnerability of a given decentralized learning architecture to MIA. In this study, we extensively explore the vulnerability to MIA of various decentralized learning architectures by varying the graph structure (e.g number of neighbors), the graph dynamics, and the aggregation strategy, across diverse datasets and data distributions. Our key finding, which to the best of our knowledge we are the first to report, is that the vulnerability to MIA is heavily correlated to (i) the local model mixing strategy performed by each node upon reception of models from neighboring nodes and (ii) the global mixing properties of the communication graph. We illustrate these results experimentally using four datasets and by theoretically analyzing the mixing properties of various decentralized architectures. Our paper draws a set of lessons learned for devising decentralized learning systems that reduce by design the vulnerability to MIA.","tags":["CNRS-LIRIS"],"title":"Scrutinizing the Vulnerability of Decentralized Learning to Membership Inference Attacks","type":"publication"},{"authors":["Paul Mangold","Alain Durmus","Aymeric Dieuleveut","Sergey Samsonov","Eric Moulines"],"categories":null,"content":"","date":1733097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733097600,"objectID":"bc5d10cfd7f60d1891a315dcf554e41f","permalink":"https://redeem-pepria.github.io/en/publication/mangold-refined-analysis-federated-2024/","publishdate":"2025-01-28T21:08:55.786645Z","relpermalink":"/en/publication/mangold-refined-analysis-federated-2024/","section":"publication","summary":"In this paper, we present a novel analysis of FedAvg with constant step size, relying on the Markov property of the underlying process. We demonstrate that the global iterates of the algorithm converge to a stationary distribution and analyze its resulting bias and variance relative to the problem's solution. We provide a first-order expansion of the bias in both homogeneous and heterogeneous settings. Interestingly, this bias decomposes into two distinct components: one that depends solely on stochastic gradient noise and another on client heterogeneity. Finally, we introduce a new algorithm based on the Richardson-Romberg extrapolation technique to mitigate this bias.","tags":["X"],"title":"Refined Analysis of Federated Averaging's Bias and Federated Richardson-Romberg Extrapolation","type":"publication"},{"authors":["Julien Nicolas","César Sabater","Mohamed Maouche","Sonia Ben Mokhtar","Mark Coates"],"categories":null,"content":"","date":1732579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1732579200,"objectID":"3e6b5d16fa1f7c6b9d5d05ebe7ee963d","permalink":"https://redeem-pepria.github.io/en/publication/nicolas-differentially-private-decentralized-2024/","publishdate":"2025-01-28T21:08:55.817719Z","relpermalink":"/en/publication/nicolas-differentially-private-decentralized-2024/","section":"publication","summary":"The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. As modern datasets contain sensitive private information, we need to give formal guarantees on the possible privacy leaks caused by this method. This paper focuses on enhancing privacy preserving variants of the method. We propose a strategy to reduce the variance of the noise introduced to achieve Differential Privacy (DP). We also adapt the method to a decentralized framework with a low computational and communication overhead, while preserving the accuracy. We leverage Secure Aggregation (a form of Multi-Party Computation) to allow the algorithm to perform computations using data distributed among multiple users or devices, without revealing individual data. We show that it is possible to use a noise scale in the decentralized setting that is similar to the one in the centralized setting. We improve upon existing convergence bounds for both the centralized and decentralized versions. The proposed method is especially relevant for decentralized applications such as distributed recommender systems, where privacy concerns are paramount.","tags":["CNRS-LIRIS"],"title":"Differentially Private and Decentralized Randomized Power Method","type":"publication"},{"authors":["Renaud Gaucher","Aymeric Dieuleveut","Hadrien Hendrikx"],"categories":null,"content":"","date":1728864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728864000,"objectID":"f646ebc72c834309ac09b556aaa68544","permalink":"https://redeem-pepria.github.io/en/publication/gaucher-achieving-optimal-breakdown-2024/","publishdate":"2025-01-28T21:08:55.692959Z","relpermalink":"/en/publication/gaucher-achieving-optimal-breakdown-2024/","section":"publication","summary":"Distributed approaches have many computational benefits, but they are vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly with one another. We investigate the notion of breakdown point, and show an upper bound on the number of adversaries that decentralized algorithms can tolerate. We introduce $ mathrmCGtextasciicircum +$, an algorithm at the intersection of $ mathrmClippedGossip$ and $ mathrmNNA$, two popular approaches for robust decentralized learning. $ mathrmCGtextasciicircum +$ meets our upper bound, and thus obtains optimal robustness guarantees, whereas neither of the existing two does. We provide experimental evidence for this gap by presenting an attack tailored to sparse graphs which breaks $ mathrmNNA$ but against which $ mathrmCGtextasciicircum +$ is robust.","tags":["X"],"title":"Achieving Optimal Breakdown for Byzantine Robust Gossip","type":"publication"},{"authors":["Constantin Philippenko","Kevin Scaman","Laurent Massoulié"],"categories":null,"content":"","date":1726185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726185600,"objectID":"0380a55c1c6edc1cbe09f546a4ef24d5","permalink":"https://redeem-pepria.github.io/en/publication/philippenko-indepth-analysis-lowrank-2024/","publishdate":"2025-01-28T21:08:55.832912Z","relpermalink":"/en/publication/philippenko-indepth-analysis-lowrank-2024/","section":"publication","summary":"We analyze a distributed algorithm to compute a low-rank matrix factorization on $N$ clients, each holding a local dataset $ mathbfStextasciicircum i  in  mathbbRtextasciicircumn_i  times d$, mathematically, we seek to solve $min_ mathbfUtextasciicircum i  in  mathbbRtextasciicircumn_i times r,  mathbfV in  mathbbRtextasciicircumd  times r   frac12  sum_i=1textasciicircum N  | mathbfStextasciicircum i -  mathbfUtextasciicircum i  mathbfVtextasciicircum top |textasciicircum 2_ textF$. Considering a power initialization of $ mathbfV$, we rewrite the previous smooth non-convex problem into a smooth strongly-convex problem that we solve using a parallel Nesterov gradient descent potentially requiring a single step of communication at the initialization step. For any client $i$ in $1,  dots, N$, we obtain a global $ mathbfV$ in $ mathbbRtextasciicircumd  times r$ common to all clients and a local variable $ mathbfUtextasciicircum i$ in $ mathbbRtextasciicircumn_i  times r$. We provide a linear rate of convergence of the excess loss which depends on $ sigma_ max /  sigma_r$, where $ sigma_r$ is the $rtextasciicircum mathrmth$ singular value of the concatenation $ mathbfS$ of the matrices $( mathbfStextasciicircum i)_i=1textasciicircum N$. This result improves the rates of convergence given in the literature, which depend on $ sigma_ maxtextasciicircum 2 /  sigma_ mintextasciicircum 2$. We provide an upper bound on the Frobenius-norm error of reconstruction under the power initialization strategy. We complete our analysis with experiments on both synthetic and real data.","tags":["INRIA-ARGO"],"title":"In-Depth Analysis of Low-rank Matrix Factorisation in a Federated Setting","type":"publication"},{"authors":["Batiste Le Bars","Aurélien Bellet","Marc Tommasi","Kevin Scaman","Giovanni Neglia"],"categories":null,"content":"","date":1721520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721520000,"objectID":"84184af5518df1a268fc37fb499166f5","permalink":"https://redeem-pepria.github.io/en/publication/lebars-improved-stability-generalization-2024/","publishdate":"2025-01-28T21:08:55.755607Z","relpermalink":"/en/publication/lebars-improved-stability-generalization-2024/","section":"publication","summary":"This paper presents a new generalization error analysis for Decentralized Stochastic Gradient Descent (D-SGD) based on algorithmic stability. The obtained results overhaul a series of recent works that suggested an increased instability due to decentralization and a detrimental impact of poorly-connected communication graphs on generalization. On the contrary, we show, for convex, strongly convex and non-convex functions, that D-SGD can always recover generalization bounds analogous to those of classical SGD, suggesting that the choice of graph does not matter. We then argue that this result is coming from a worst-case analysis, and we provide a refined optimization-dependent generalization bound for general convex functions. This new bound reveals that the choice of graph can in fact improve the worst-case bound in certain regimes, and that surprisingly, a poorly-connected graph can even be beneficial for generalization.","tags":["INRIA-ARGO","INRIA-MAGNET"],"title":"Improved Stability and Generalization Guarantees of the Decentralized SGD Algorithm","type":"publication"},{"authors":["Rémi Leluc","Aymeric Dieuleveut","François Portier","Johan Segers","Aigerim Zhuman"],"categories":null,"content":"","date":1720396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720396800,"objectID":"bee954922ceea9c15ee608a066cddfff","permalink":"https://redeem-pepria.github.io/en/publication/leluc-sliced-wasserstein-estimation-spherical-2024-a/","publishdate":"2025-01-28T21:08:55.771315Z","relpermalink":"/en/publication/leluc-sliced-wasserstein-estimation-spherical-2024-a/","section":"publication","summary":"The Sliced-Wasserstein (SW) distance between probability measures is defined as the average of the Wasserstein distances resulting for the associated one-dimensional projections. As a consequence, the SW distance can be written as an integral with respect to the uniform measure on the sphere and the Monte Carlo framework can be employed for calculating the SW distance. Spherical harmonics are polynomials on the sphere that form an orthonormal basis of the set of square-integrable functions on the sphere. Putting these two facts together, a new Monte Carlo method, hereby referred to as Spherical Harmonics Control Variates (SHCV), is proposed for approximating the SW distance using spherical harmonics as control variates. The resulting approach is shown to have good theoretical properties, e.g., a no-error property for Gaussian measures under a certain form of linear dependency between the variables. Moreover, an improved rate of convergence, compared to Monte Carlo, is established for general measures. The convergence analysis relies on the Lipschitz property associated to the SW integrand. Several numerical experiments demonstrate the superior performance of SHCV against state-of-the-art methods for SW distance computation.","tags":null,"title":"Sliced-Wasserstein Estimation with Spherical Harmonics as Control Variates","type":"publication"},{"authors":["Pierre Jobic","Aurélien Mayoue","Sara Tucci-Piergiovanni","François Terrier"],"categories":null,"content":"","date":1719187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719187200,"objectID":"2d2da173f8132d8b7926dcf5efe4174f","permalink":"https://redeem-pepria.github.io/en/publication/jobic-extending-scope-gradient-2024-a/","publishdate":"2025-01-28T21:08:55.739435Z","relpermalink":"/en/publication/jobic-extending-scope-gradient-2024-a/","section":"publication","summary":"Federated Learning (FL) has gained prominence as a decentralized and privacy-preserving paradigm that enables multiple clients to collaboratively train a machine learning model under the supervision of a central server. Instead of centralizing the data, clients keep their data locally and share only model parameters during multiple communication rounds. However, recent attacks, such as gradient reconstruction attacks (GRAs) show privacy issues when an attacker knows the communication of a client. In the literature, these privacy issues are mainly explored when clients compute new parameters using a single gradient descent step on their data (FedSGD) and then send them back to the remote server. In a more realistic scenario, the clients' protocol is based on several gradient descent steps (FedAvg). This protocol adds intermediate computation steps, which are unknown from the attacker, thus making GRAs less successful. In this incremental paper, we conduct exhaustive experiments on four state-of-the-art attacks under the FedAvg protocol, on a very basic and a more complex neural network (ResNet-18) with CIFAR100 dataset. These experiments provide the following results 1) a privacy-utility trade-off analysis, 2) insights on the choice of attacks' hyperparameters, 3) the client's local learning rate has little impact on attacks' effectiveness 4) a proof that the privacy risk is not necessarily decreasing over rounds, contrary to common belief.","tags":["CEA-distrAI"],"title":"Extending the Scope of Gradient Reconstruction Attacks in Federated Averaging","type":"publication"},{"authors":["Imane Taibi","Jan Ramon"],"categories":null,"content":"","date":1719187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719187200,"objectID":"0adace4ea82930a11bc6e9c5458732b5","permalink":"https://redeem-pepria.github.io/en/publication/taibi-honest-fraction-differential-2024/","publishdate":"2025-01-29T13:18:02.819657Z","relpermalink":"/en/publication/taibi-honest-fraction-differential-2024/","section":"publication","summary":"Over the last decades, differential privacy (DP) has become a standard notion of privacy. It allows to measure how much sensitive information an adversary could infer from a result (statistical model, prediction, etc.) he obtains. In privacy-preserving federated machine learning, one aims to learn a statistical model from data owned by multiple data owners without revealing their sensitive data. A common strategy is to use secure multi-party computation (SMPC) to avoid revealing intermediate results. However, DP assumes a very strong adversary who is able to know all information in the dataset except the targeted secret, while most SMPC methods assume a clearly less strong adversary, e.g., it is common to assume that the adversary has bounded computational power and can corrupt only a minority of the data owners (honest majority). As a chain is not stronger than its weakest part, in such combinations the DP provides an overly strong protection at an unnecessarily high cost in terms of utility. We propose honest fraction differential privacy, which is similar to differential privacy but assumes that the adversary can only collude with data owners covering part of the data. This assumption is very similar to the assumptions made by many SMPC strategies. We illustrate this idea by considering the application to the specific task of unregularized linear regression without bias on sufficiently large datasets.","tags":null,"title":"Honest Fraction Differential Privacy","type":"publication"},{"authors":["Renaud Gaucher","Hadrien Hendrikx","Aymeric Dieuleveut"],"categories":null,"content":"","date":1714953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714953600,"objectID":"378cb47ce6e302b69db03dd8e8404b82","permalink":"https://redeem-pepria.github.io/en/publication/gaucher-byzantine-robust-gossip-insights-2024/","publishdate":"2025-01-28T21:08:55.709425Z","relpermalink":"/en/publication/gaucher-byzantine-robust-gossip-insights-2024/","section":"publication","summary":"Distributed approaches have many computational benefits, but they are vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly with one another. We leverage the so-called dual approach to design a general robust decentralized optimization method. We provide both global and local clipping rules in the special case of average consensus, with tight convergence guarantees. These clipping rules are practical, and yield results that finely characterize the impact of Byzantine nodes, highlighting for instance a qualitative difference in convergence between global and local clipping thresholds. Lastly, we demonstrate that they can serve as a basis for designing efficient attacks.","tags":["X"],"title":"Byzantine-Robust Gossip: Insights from a Dual Approach","type":"publication"},{"authors":["Mahmoud Hegazy","Rémi Leluc","Cheuk Ting Li","Aymeric Dieuleveut"],"categories":null,"content":"","date":1713398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713398400,"objectID":"126be16d00fb8c8afe8ff697607edd26","permalink":"https://redeem-pepria.github.io/en/publication/hegazy-compression-exact-error-2024/","publishdate":"2025-01-28T21:08:55.724095Z","relpermalink":"/en/publication/hegazy-compression-exact-error-2024/","section":"publication","summary":"Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing.","tags":["X"],"title":"Compression with Exact Error Distribution for Federated Learning","type":"publication"},{"authors":["Kevin Scaman","Mathieu Even","Batiste Le Bars","Laurent Massoulié"],"categories":null,"content":"","date":1713398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713398400,"objectID":"e27874dabf721c07999e6e9d9002c96c","permalink":"https://redeem-pepria.github.io/en/publication/scaman-minimax-excess-risk-2024/","publishdate":"2025-01-28T21:08:55.84915Z","relpermalink":"/en/publication/scaman-minimax-excess-risk-2024/","section":"publication","summary":"In this paper, our aim is to analyse the generalization capabilities of first-order methods for statistical learning in multiple, different yet related, scenarios including supervised learning, transfer learning, robust learning and federated learning. To do so, we provide sharp upper and lower bounds for the minimax excess risk of strongly convex and smooth statistical learning when the gradient is accessed through partial observations given by a data-dependent oracle. This novel class of oracles can query the gradient with any given data distribution, and is thus well suited to scenarios in which the training data distribution does not match the target (or test) distribution. In particular, our upper and lower bounds are proportional to the smallest mean square error achievable by gradient estimators, thus allowing us to easily derive multiple sharp bounds in the aforementioned scenarios using the extensive literature on parameter estimation.","tags":["INRIA-ARGO"],"title":"Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles","type":"publication"},{"authors":["Yann Fraboni","Martin Van Waerebeke","Kevin Scaman","Richard Vidal","Laetitia Kameni","Marco Lorenzi"],"categories":null,"content":"","date":1713398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713398400,"objectID":"a3b5038611e3918dcf9cbd6a01f65cdb","permalink":"https://redeem-pepria.github.io/en/publication/fraboni-sifu-sequential-informed-2024/","publishdate":"2025-01-28T21:08:55.677079Z","relpermalink":"/en/publication/fraboni-sifu-sequential-informed-2024/","section":"publication","summary":"Machine Unlearning (MU) is an increasingly important topic in machine learning safety, aiming at removing the contribution of a given data point from a training procedure. Federated Unlearning (FU) consists in extending MU to unlearn a given client’s contribution from a federated training routine. While several FU methods have been proposed, we currently lack a general approach providing formal unlearning guarantees to the FedAvg routine, while ensuring scalability and generalization beyond the convex assumption on the clients’ loss functions. We aim at filling this gap by proposing SIFU (Sequential Informed Federated Unlearning), a new FU method applying to both convex and non-convex optimization regimes. SIFU naturally applies to FedAvg without additional computational cost for the clients and provides formal guarantees on the quality of the unlearning task. We provide a theoretical analysis of the unlearning properties of SIFU, and practically demonstrate its effectiveness as compared to a panel of unlearning methods from the state-of-the-art.","tags":["INRIA-ARGO"],"title":"SIFU: Sequential Informed Federated Unlearning for Efficient and Provable Client Unlearning in Federated Optimization","type":"publication"},{"authors":["Vitalii Emelianov","Michaël Perrot"],"categories":null,"content":"","date":1707091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707091200,"objectID":"52593d893d015e954e4d94dfc8e4e9f1","permalink":"https://redeem-pepria.github.io/en/publication/emelianov-impact-output-perturbation-2024/","publishdate":"2025-01-28T21:08:55.659835Z","relpermalink":"/en/publication/emelianov-impact-output-perturbation-2024/","section":"publication","summary":"We theoretically study how differential privacy interacts with both individual and group fairness in binary linear classification. More precisely, we focus on the output perturbation mechanism, a classic approach in privacy-preserving machine learning. We derive high-probability bounds on the level of individual and group fairness that the perturbed models can achieve compared to the original model. Hence, for individual fairness, we prove that the impact of output perturbation on the level of fairness is bounded but grows with the dimension of the model. For group fairness, we show that this impact is determined by the distribution of so-called angular margins, that is signed margins of the non-private model re-scaled by the norm of each example.","tags":["INRIA-MAGNET"],"title":"On the Impact of Output Perturbation on Fairness in Binary Linear Classification","type":"publication"}]