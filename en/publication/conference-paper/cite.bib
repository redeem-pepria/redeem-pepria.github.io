@inproceedings{clainDecentralizedFederatedDataset2025,
  title = {Decentralized {{Federated Dataset Dictionary Learning}} for {{Multi-Source Domain Adaptation}}},
  booktitle = {{{ICASSP}} 2025-2025 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Clain, Rebecca and Fernandes Montesuma, Eduardo and Ngole Mboula, Fred Maurice},
  date = {2025-04},
  location = {India},
  keywords = {CEA-distrAI},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\_\Clain et al_2025_Decentralized Federated Dataset Dictionary Learning for Multi-Source Domain.pdf}
}

@incollection{draganCertificatesSubquadraticTimeComputation2025,
  title = {Certificates in {{P}} and {{Subquadratic-Time Computation}} of {{Radius}}, {{Diameter}}, and All {{Eccentricities}} in {{Graphs}}},
  booktitle = {Proceedings of the 2025 {{Annual ACM-SIAM Symposium}} on {{Discrete Algorithms}} ({{SODA}})},
  author = {Dragan, Feodor and Ducoffe, Guillaume and Habib, Michel and Viennot, Laurent},
  date = {2025-01},
  series = {Proceedings},
  pages = {2157--2193},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611978322.70},
  url = {https://epubs.siam.org/doi/10.1137/1.9781611978322.70},
  urldate = {2025-01-27},
  abstract = {In the context of fine-grained complexity, we investigate the notion of certificate enabling faster polynomialtime algorithms. We specifically target radius (minimum eccentricity), diameter (maximum eccentricity), and all-eccentricity computations for which quadratic-time lower bounds are known under plausible conjectures. In each case, we introduce a notion of certificate as a specific set of nodes from which appropriate bounds on all eccentricities can be derived in subquadratic time when this set has sublinear size. The existence of small certificates is a barrier against SETH-based lower bounds for these problems. We indeed prove that for graph classes with small certificates, there exist randomized subquadratic-time algorithms for computing the radius, the diameter, and all eccentricities respectively.Moreover, these notions of certificates are tightly related to algorithms probing the graph through one- to-all distance queries and allow to explain the efficiency of practical radius and diameter algorithms from the literature. Our formalization enables a novel primal-dual analysis of a classical approach for diameter computation that leads to algorithms for radius, diameter and all eccentricities with theoretical guarantees with respect to certain graph parameters. This is complemented by experimental results on various types of real-world graphs showing that these parameters appear to be low in practice. Finally, we obtain refined results for several graph classes.*This work was supported by the French ANR projects ANR-22-CE48-0001 (TEMPOGRAL), ANR-24-CE48-4377 (GODASse) and ANR-23-PEIA-005 (REDEEM).},
  keywords = {INRIA-ARGO},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\Society for Industrial and Applied Mathematics\Dragan et al_2025_Certificates in P and Subquadratic-Time Computation of Radius, Diameter, and.pdf}
}

@online{emelianovImpactOutputPerturbation2024,
  title = {On the {{Impact}} of {{Output Perturbation}} on {{Fairness}} in {{Binary Linear Classification}}},
  author = {Emelianov, Vitalii and Perrot, Michaël},
  date = {2024-02-05},
  eprint = {2402.03011},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.03011},
  url = {http://arxiv.org/abs/2402.03011},
  urldate = {2025-01-27},
  abstract = {We theoretically study how differential privacy interacts with both individual and group fairness in binary linear classification. More precisely, we focus on the output perturbation mechanism, a classic approach in privacy-preserving machine learning. We derive high-probability bounds on the level of individual and group fairness that the perturbed models can achieve compared to the original model. Hence, for individual fairness, we prove that the impact of output perturbation on the level of fairness is bounded but grows with the dimension of the model. For group fairness, we show that this impact is determined by the distribution of so-called angular margins, that is signed margins of the non-private model re-scaled by the norm of each example.},
  pubstate = {prepublished},
  keywords = {INRIA-MAGNET},
  file = {C\:\\Users\\cg228481\\Documents\\50biblio\\zotero\\arXiv\\Emelianov_Perrot_2024_On the Impact of Output Perturbation on Fairness in Binary Linear Classification.pdf;C\:\\Users\\cg228481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\R8VZ7XWW\\2402.html}
}

@inproceedings{fraboniSIFUSequentialInformed2024,
  title = {{{SIFU}}: {{Sequential Informed Federated Unlearning}} for {{Efficient}} and {{Provable Client Unlearning}} in {{Federated Optimization}}},
  shorttitle = {{{SIFU}}},
  booktitle = {Proceedings of {{The}} 27th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Fraboni, Yann and Waerebeke, Martin Van and Scaman, Kevin and Vidal, Richard and Kameni, Laetitia and Lorenzi, Marco},
  date = {2024-04-18},
  pages = {3457--3465},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v238/fraboni24a.html},
  urldate = {2025-01-27},
  abstract = {Machine Unlearning (MU) is an increasingly important topic in machine learning safety, aiming at removing the contribution of a given data point from a training procedure. Federated Unlearning (FU) consists in extending MU to unlearn a given client’s contribution from a federated training routine. While several FU methods have been proposed, we currently lack a general approach providing formal unlearning guarantees to the FedAvg routine, while ensuring scalability and generalization beyond the convex assumption on the clients’ loss functions. We aim at filling this gap by proposing SIFU (Sequential Informed Federated Unlearning), a new FU method applying to both convex and non-convex optimization regimes. SIFU naturally applies to FedAvg without additional computational cost for the clients and provides formal guarantees on the quality of the unlearning task. We provide a theoretical analysis of the unlearning properties of SIFU, and practically demonstrate its effectiveness as compared to a panel of unlearning methods from the state-of-the-art.},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english},
  keywords = {INRIA-ARGO},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\PMLR\Fraboni et al_2024_SIFU.pdf}
}

@online{gaucherAchievingOptimalBreakdown2024,
  title = {Achieving {{Optimal Breakdown}} for {{Byzantine Robust Gossip}}},
  author = {Gaucher, Renaud and Dieuleveut, Aymeric and Hendrikx, Hadrien},
  date = {2024-10-14},
  eprint = {2410.10418},
  eprinttype = {arXiv},
  eprintclass = {math},
  doi = {10.48550/arXiv.2410.10418},
  url = {http://arxiv.org/abs/2410.10418},
  urldate = {2025-01-27},
  abstract = {Distributed approaches have many computational benefits, but they are vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly with one another. We investigate the notion of breakdown point, and show an upper bound on the number of adversaries that decentralized algorithms can tolerate. We introduce \$\textbackslash mathrm\{CG\}\textasciicircum +\$, an algorithm at the intersection of \$\textbackslash mathrm\{ClippedGossip\}\$ and \$\textbackslash mathrm\{NNA\}\$, two popular approaches for robust decentralized learning. \$\textbackslash mathrm\{CG\}\textasciicircum +\$ meets our upper bound, and thus obtains optimal robustness guarantees, whereas neither of the existing two does. We provide experimental evidence for this gap by presenting an attack tailored to sparse graphs which breaks \$\textbackslash mathrm\{NNA\}\$ but against which \$\textbackslash mathrm\{CG\}\textasciicircum +\$ is robust.},
  pubstate = {prepublished},
  keywords = {X},
  file = {C\:\\Users\\cg228481\\Documents\\50biblio\\zotero\\arXiv\\Gaucher et al_2024_Achieving Optimal Breakdown for Byzantine Robust Gossip.pdf;C\:\\Users\\cg228481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\3XBX3H78\\2410.html}
}

@online{gaucherByzantineRobustGossipInsights2024,
  title = {Byzantine-{{Robust Gossip}}: {{Insights}} from a {{Dual Approach}}},
  shorttitle = {Byzantine-{{Robust Gossip}}},
  author = {Gaucher, Renaud and Hendrikx, Hadrien and Dieuleveut, Aymeric},
  date = {2024-05-06},
  eprint = {2405.03449},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.03449},
  url = {http://arxiv.org/abs/2405.03449},
  urldate = {2025-01-27},
  abstract = {Distributed approaches have many computational benefits, but they are vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly with one another. We leverage the so-called dual approach to design a general robust decentralized optimization method. We provide both global and local clipping rules in the special case of average consensus, with tight convergence guarantees. These clipping rules are practical, and yield results that finely characterize the impact of Byzantine nodes, highlighting for instance a qualitative difference in convergence between global and local clipping thresholds. Lastly, we demonstrate that they can serve as a basis for designing efficient attacks.},
  pubstate = {prepublished},
  keywords = {X},
  file = {C\:\\Users\\cg228481\\Documents\\50biblio\\zotero\\arXiv\\Gaucher et al_2024_Byzantine-Robust Gossip.pdf;C\:\\Users\\cg228481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\F3SWBWBM\\2405.html}
}

@inproceedings{hegazyCompressionExactError2024,
  title = {Compression with {{Exact Error Distribution}} for {{Federated Learning}}},
  booktitle = {Proceedings of {{The}} 27th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Hegazy, Mahmoud and Leluc, Rémi and Li, Cheuk Ting and Dieuleveut, Aymeric},
  date = {2024-04-18},
  pages = {613--621},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v238/hegazy24a.html},
  urldate = {2025-01-27},
  abstract = {Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing.},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english},
  keywords = {X},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\PMLR\Hegazy et al_2024_Compression with Exact Error Distribution for Federated Learning.pdf}
}

@inproceedings{jobicExtendingScopeGradient2024a,
  title = {Extending the {{Scope}} of {{Gradient Reconstruction Attacks}} in {{Federated Averaging}}},
  booktitle = {Proceedings of the 2024 {{ACM Workshop}} on {{Information Hiding}} and {{Multimedia Security}}},
  author = {Jobic, Pierre and Mayoue, Aurélien and Tucci-Piergiovanni, Sara and Terrier, François},
  date = {2024-06-24},
  series = {{{IH}}\&amp;{{MMSec}} '24},
  pages = {235--246},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3658664.3659636},
  url = {https://dl.acm.org/doi/10.1145/3658664.3659636},
  urldate = {2025-01-27},
  abstract = {Federated Learning (FL) has gained prominence as a decentralized and privacy-preserving paradigm that enables multiple clients to collaboratively train a machine learning model under the supervision of a central server. Instead of centralizing the data, clients keep their data locally and share only model parameters during multiple communication rounds. However, recent attacks, such as gradient reconstruction attacks (GRAs) show privacy issues when an attacker knows the communication of a client. In the literature, these privacy issues are mainly explored when clients compute new parameters using a single gradient descent step on their data (FedSGD) and then send them back to the remote server. In a more realistic scenario, the clients' protocol is based on several gradient descent steps (FedAvg). This protocol adds intermediate computation steps, which are unknown from the attacker, thus making GRAs less successful. In this incremental paper, we conduct exhaustive experiments on four state-of-the-art attacks under the FedAvg protocol, on a very basic and a more complex neural network (ResNet-18) with CIFAR100 dataset. These experiments provide the following results 1) a privacy-utility trade-off analysis, 2) insights on the choice of attacks' hyperparameters, 3) the client's local learning rate has little impact on attacks' effectiveness 4) a proof that the privacy risk is not necessarily decreasing over rounds, contrary to common belief.},
  isbn = {9798400706370},
  keywords = {CEA-distrAI},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\Association for Computing Machinery\Jobic et al_2024_Extending the Scope of Gradient Reconstruction Attacks in Federated Averaging2.pdf}
}

@inproceedings{lebarsImprovedStabilityGeneralization2024,
  title = {Improved Stability and Generalization Guarantees of the Decentralized {{SGD}} Algorithm},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Le Bars, Batiste and Bellet, Aurélien and Tommasi, Marc and Scaman, Kevin and Neglia, Giovanni},
  date = {2024-07-21},
  series = {{{ICML}}'24},
  volume = {235},
  pages = {26215--26240},
  publisher = {JMLR.org},
  location = {Vienna, Austria},
  abstract = {This paper presents a new generalization error analysis for Decentralized Stochastic Gradient Descent (D-SGD) based on algorithmic stability. The obtained results overhaul a series of recent works that suggested an increased instability due to decentralization and a detrimental impact of poorly-connected communication graphs on generalization. On the contrary, we show, for convex, strongly convex and non-convex functions, that D-SGD can always recover generalization bounds analogous to those of classical SGD, suggesting that the choice of graph does not matter. We then argue that this result is coming from a worst-case analysis, and we provide a refined optimization-dependent generalization bound for general convex functions. This new bound reveals that the choice of graph can in fact improve the worst-case bound in certain regimes, and that surprisingly, a poorly-connected graph can even be beneficial for generalization.},
  keywords = {INRIA-ARGO,INRIA-MAGNET},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\arXiv\Bars et al_2024_Improved Stability and Generalization Guarantees of the Decentralized SGD.pdf}
}

@inproceedings{lelucSlicedWassersteinEstimationSpherical2024a,
  title = {Sliced-{{Wasserstein Estimation}} with {{Spherical Harmonics}} as {{Control Variates}}},
  booktitle = {Proceedings of the 41st {{International Conference}} on {{Machine Learning}}},
  author = {Leluc, Rémi and Dieuleveut, Aymeric and Portier, François and Segers, Johan and Zhuman, Aigerim},
  date = {2024-07-08},
  pages = {27191--27214},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v235/leluc24a.html},
  urldate = {2025-01-27},
  abstract = {The Sliced-Wasserstein (SW) distance between probability measures is defined as the average of the Wasserstein distances resulting for the associated one-dimensional projections. As a consequence, the SW distance can be written as an integral with respect to the uniform measure on the sphere and the Monte Carlo framework can be employed for calculating the SW distance. Spherical harmonics are polynomials on the sphere that form an orthonormal basis of the set of square-integrable functions on the sphere. Putting these two facts together, a new Monte Carlo method, hereby referred to as Spherical Harmonics Control Variates (SHCV), is proposed for approximating the SW distance using spherical harmonics as control variates. The resulting approach is shown to have good theoretical properties, e.g., a no-error property for Gaussian measures under a certain form of linear dependency between the variables. Moreover, an improved rate of convergence, compared to Monte Carlo, is established for general measures. The convergence analysis relies on the Lipschitz property associated to the SW integrand. Several numerical experiments demonstrate the superior performance of SHCV against state-of-the-art methods for SW distance computation.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\PMLR\Leluc et al_2024_Sliced-Wasserstein Estimation with Spherical Harmonics as Control Variates.pdf}
}

@online{mangoldRefinedAnalysisFederated2024,
  title = {Refined {{Analysis}} of {{Federated Averaging}}'s {{Bias}} and {{Federated Richardson-Romberg Extrapolation}}},
  author = {Mangold, Paul and Durmus, Alain and Dieuleveut, Aymeric and Samsonov, Sergey and Moulines, Eric},
  date = {2024-12-02},
  eprint = {2412.01389},
  eprinttype = {arXiv},
  eprintclass = {stat},
  doi = {10.48550/arXiv.2412.01389},
  url = {http://arxiv.org/abs/2412.01389},
  urldate = {2025-01-27},
  abstract = {In this paper, we present a novel analysis of FedAvg with constant step size, relying on the Markov property of the underlying process. We demonstrate that the global iterates of the algorithm converge to a stationary distribution and analyze its resulting bias and variance relative to the problem's solution. We provide a first-order expansion of the bias in both homogeneous and heterogeneous settings. Interestingly, this bias decomposes into two distinct components: one that depends solely on stochastic gradient noise and another on client heterogeneity. Finally, we introduce a new algorithm based on the Richardson-Romberg extrapolation technique to mitigate this bias.},
  pubstate = {prepublished},
  keywords = {X},
  file = {C\:\\Users\\cg228481\\Documents\\50biblio\\zotero\\arXiv\\Mangold et al_2024_Refined Analysis of Federated Averaging's Bias and Federated Richardson-Romberg.pdf;C\:\\Users\\cg228481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\FULU6Q7V\\2412.html}
}

@unpublished{mosquedagonzalezMitigationSybilbasedPoisoning2025,
  title = {Mitigation of {{Sybil-based Poisoning Attacks}} in {{Permissionless Decentralized Learning}}},
  author = {Mosqueda González, Brandon A and Hasan, Omar and Brunie, Lionel},
  date = {2025-01},
  url = {https://hal.science/hal-04892539},
  urldate = {2025-01-27},
  abstract = {Decentralized learning enables collaborative machine learning with enhanced privacy by allowing participants to train models locally and share updates for aggregation instead of sharing raw data. However, such systems are vulnerable to poisoning attacks that may compromise the learning process. This threat becomes even more severe when combined with sybil attacks, where adversaries contribute numerous malicious updates with minimal effort, amplifying their impact. To overcome these challenges, particularly in the permissionless setup, we propose SyDeLP, a blockchain-enabled protocol for decentralized learning. SyDeLP integrates byzantine tolerant aggregation for poisoning mitigation with a novel Verifiable Delay Puzzle to counter sybil attacks requiring Proofs of Work to participate. Honest behavior is incentivized by dynamically reducing puzzle difficulty, decreasing the computational burden for honest nodes over time. Empirical evaluations conducted on two benchmark datasets across four types of poisoning attack demonstrate that SyDeLP consistently outperforms existing solutions in terms of poisoning resilience.},
  keywords = {CNRS-LIRIS},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\_\Mosqueda González et al_2025_Mitigation of Sybil-based Poisoning Attacks in Permissionless Decentralized.pdf}
}

@online{nicolasDifferentiallyPrivateDecentralized2024,
  title = {Differentially Private and Decentralized Randomized Power Method},
  author = {Nicolas, Julien and Sabater, César and Maouche, Mohamed and Mokhtar, Sonia Ben and Coates, Mark},
  date = {2024-11-26},
  eprint = {2411.01931},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.01931},
  url = {http://arxiv.org/abs/2411.01931},
  urldate = {2025-01-27},
  abstract = {The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. As modern datasets contain sensitive private information, we need to give formal guarantees on the possible privacy leaks caused by this method. This paper focuses on enhancing privacy preserving variants of the method. We propose a strategy to reduce the variance of the noise introduced to achieve Differential Privacy (DP). We also adapt the method to a decentralized framework with a low computational and communication overhead, while preserving the accuracy. We leverage Secure Aggregation (a form of Multi-Party Computation) to allow the algorithm to perform computations using data distributed among multiple users or devices, without revealing individual data. We show that it is possible to use a noise scale in the decentralized setting that is similar to the one in the centralized setting. We improve upon existing convergence bounds for both the centralized and decentralized versions. The proposed method is especially relevant for decentralized applications such as distributed recommender systems, where privacy concerns are paramount.},
  pubstate = {prepublished},
  keywords = {CNRS-LIRIS},
  file = {C\:\\Users\\cg228481\\Documents\\50biblio\\zotero\\arXiv\\Nicolas et al_2024_Differentially private and decentralized randomized power method.pdf;C\:\\Users\\cg228481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\KADJKYXA\\2411.html}
}

@online{philippenkoIndepthAnalysisLowrank2024,
  title = {In-Depth {{Analysis}} of {{Low-rank Matrix Factorisation}} in a {{Federated Setting}}},
  author = {Philippenko, Constantin and Scaman, Kevin and Massoulié, Laurent},
  date = {2024-09-13},
  eprint = {2409.08771},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.08771},
  url = {http://arxiv.org/abs/2409.08771},
  urldate = {2025-01-27},
  abstract = {We analyze a distributed algorithm to compute a low-rank matrix factorization on \$N\$ clients, each holding a local dataset \$\textbackslash mathbf\{S\}\textasciicircum i \textbackslash in \textbackslash mathbb\{R\}\textasciicircum\{n\_i \textbackslash times d\}\$, mathematically, we seek to solve \$min\_\{\textbackslash mathbf\{U\}\textasciicircum i \textbackslash in \textbackslash mathbb\{R\}\textasciicircum\{n\_i\textbackslash times r\}, \textbackslash mathbf\{V\}\textbackslash in \textbackslash mathbb\{R\}\textasciicircum\{d \textbackslash times r\} \} \textbackslash frac\{1\}\{2\} \textbackslash sum\_\{i=1\}\textasciicircum N \textbackslash |\textbackslash mathbf\{S\}\textasciicircum i - \textbackslash mathbf\{U\}\textasciicircum i \textbackslash mathbf\{V\}\textasciicircum\textbackslash top\textbackslash |\textasciicircum 2\_\{\textbackslash text\{F\}\}\$. Considering a power initialization of \$\textbackslash mathbf\{V\}\$, we rewrite the previous smooth non-convex problem into a smooth strongly-convex problem that we solve using a parallel Nesterov gradient descent potentially requiring a single step of communication at the initialization step. For any client \$i\$ in \$\textbackslash\{1, \textbackslash dots, N\textbackslash\}\$, we obtain a global \$\textbackslash mathbf\{V\}\$ in \$\textbackslash mathbb\{R\}\textasciicircum\{d \textbackslash times r\}\$ common to all clients and a local variable \$\textbackslash mathbf\{U\}\textasciicircum i\$ in \$\textbackslash mathbb\{R\}\textasciicircum\{n\_i \textbackslash times r\}\$. We provide a linear rate of convergence of the excess loss which depends on \$\textbackslash sigma\_\{\textbackslash max\} / \textbackslash sigma\_\{r\}\$, where \$\textbackslash sigma\_\{r\}\$ is the \$r\textasciicircum\{\textbackslash mathrm\{th\}\}\$ singular value of the concatenation \$\textbackslash mathbf\{S\}\$ of the matrices \$(\textbackslash mathbf\{S\}\textasciicircum i)\_\{i=1\}\textasciicircum N\$. This result improves the rates of convergence given in the literature, which depend on \$\textbackslash sigma\_\{\textbackslash max\}\textasciicircum 2 / \textbackslash sigma\_\{\textbackslash min\}\textasciicircum 2\$. We provide an upper bound on the Frobenius-norm error of reconstruction under the power initialization strategy. We complete our analysis with experiments on both synthetic and real data.},
  pubstate = {prepublished},
  keywords = {INRIA-ARGO},
  file = {C\:\\Users\\cg228481\\Documents\\50biblio\\zotero\\arXiv\\Philippenko et al_2024_In-depth Analysis of Low-rank Matrix Factorisation in a Federated Setting.pdf;C\:\\Users\\cg228481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\SG8H3DHU\\2409.html}
}

@inproceedings{scamanMinimaxExcessRisk2024,
  title = {Minimax {{Excess Risk}} of {{First-Order Methods}} for {{Statistical Learning}} with {{Data-Dependent Oracles}}},
  booktitle = {Proceedings of {{The}} 27th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Scaman, Kevin and Even, Mathieu and Bars, Batiste Le and Massoulie, Laurent},
  date = {2024-04-18},
  pages = {3709--3717},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v238/scaman24a.html},
  urldate = {2025-01-27},
  abstract = {In this paper, our aim is to analyse the generalization capabilities of first-order methods for statistical learning in multiple, different yet related, scenarios including supervised learning, transfer learning, robust learning and federated learning. To do so, we provide sharp upper and lower bounds for the minimax excess risk of strongly convex and smooth statistical learning when the gradient is accessed through partial observations given by a data-dependent oracle. This novel class of oracles can query the gradient with any given data distribution, and is thus well suited to scenarios in which the training data distribution does not match the target (or test) distribution. In particular, our upper and lower bounds are proportional to the smallest mean square error achievable by gradient estimators, thus allowing us to easily derive multiple sharp bounds in the aforementioned scenarios using the extensive literature on parameter estimation.},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english},
  keywords = {INRIA-ARGO},
  file = {C:\Users\cg228481\Documents\50biblio\zotero\PMLR\Scaman et al_2024_Minimax Excess Risk of First-Order Methods for Statistical Learning with.pdf}
}

@online{touatScrutinizingVulnerabilityDecentralized2024,
  title = {Scrutinizing the {{Vulnerability}} of {{Decentralized Learning}} to {{Membership Inference Attacks}}},
  author = {Touat, Ousmane and Brunon, Jezekael and Belal, Yacine and Nicolas, Julien and Maouche, Mohamed and Sabater, César and Mokhtar, Sonia Ben},
  date = {2024-12-17},
  eprint = {2412.12837},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.12837},
  url = {http://arxiv.org/abs/2412.12837},
  urldate = {2025-01-27},
  abstract = {The primary promise of decentralized learning is to allow users to engage in the training of machine learning models in a collaborative manner while keeping their data on their premises and without relying on any central entity. However, this paradigm necessitates the exchange of model parameters or gradients between peers. Such exchanges can be exploited to infer sensitive information about training data, which is achieved through privacy attacks (e.g Membership Inference Attacks -- MIA). In order to devise effective defense mechanisms, it is important to understand the factors that increase/reduce the vulnerability of a given decentralized learning architecture to MIA. In this study, we extensively explore the vulnerability to MIA of various decentralized learning architectures by varying the graph structure (e.g number of neighbors), the graph dynamics, and the aggregation strategy, across diverse datasets and data distributions. Our key finding, which to the best of our knowledge we are the first to report, is that the vulnerability to MIA is heavily correlated to (i) the local model mixing strategy performed by each node upon reception of models from neighboring nodes and (ii) the global mixing properties of the communication graph. We illustrate these results experimentally using four datasets and by theoretically analyzing the mixing properties of various decentralized architectures. Our paper draws a set of lessons learned for devising decentralized learning systems that reduce by design the vulnerability to MIA.},
  pubstate = {prepublished},
  keywords = {CNRS-LIRIS},
  file = {C\:\\Users\\cg228481\\Documents\\50biblio\\zotero\\arXiv\\Touat et al_2024_Scrutinizing the Vulnerability of Decentralized Learning to Membership.pdf;C\:\\Users\\cg228481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\DHUS7P6G\\2412.html}
}
