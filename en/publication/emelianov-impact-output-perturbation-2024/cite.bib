@online{emelianovImpactOutputPerturbation2024,
 abstract = {We theoretically study how differential privacy interacts with both individual and group fairness in binary linear classification. More precisely, we focus on the output perturbation mechanism, a classic approach in privacy-preserving machine learning. We derive high-probability bounds on the level of individual and group fairness that the perturbed models can achieve compared to the original model. Hence, for individual fairness, we prove that the impact of output perturbation on the level of fairness is bounded but grows with the dimension of the model. For group fairness, we show that this impact is determined by the distribution of so-called angular margins, that is signed margins of the non-private model re-scaled by the norm of each example.},
 author = {Emelianov, Vitalii and Perrot, Michaël},
 date = {2024-02-05},
 doi = {10.48550/arXiv.2402.03011},
 eprint = {2402.03011},
 eprintclass = {cs},
 eprinttype = {arXiv},
 file = {C\:\\Users\ģ228481\\Documents\\50biblio\\zotero\\arXiv\\Emelianov_Perrot_2024_On the Impact of Output Perturbation on Fairness in Binary Linear Classification.pdf;C\:\\Users\\2̧28481\\Documents\\50biblio\\ZOTERO_config\\Zotero\\storage\\R8VZ7XWW\\2402.html},
 keywords = {INRIA-MAGNET},
 pubstate = {prepublished},
 title = {On the Impact of Output Perturbation on Fairness in Binary Linear Classification},
 url = {http://arxiv.org/abs/2402.03011},
 urldate = {2025-01-27}
}
